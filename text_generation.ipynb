{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "text_generation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sampritich/samplerepo/blob/master/text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQU0L9jvHpBN",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation\n",
        "\n",
        "In this notebook, we are going to generate 1000 character texts, given an initial seed of characters. This will help us evaluate that how much the model has understood about word formation, english grammar and context of the initial seed.\n",
        "\n",
        "Code segments [1] to [5] are same as that in 'train.ipynb' notebook and their detailed explanation can be found over their itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP-jOJshHrjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "6cb27f12-cda2-4e3e-a8cf-82ea5d557865"
      },
      "source": [
        "!wget https://www.dropbox.com/s/9c02j9o9urumi58/saved_models.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-15 12:52:38--  https://www.dropbox.com/s/9c02j9o9urumi58/saved_models.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/9c02j9o9urumi58/saved_models.zip [following]\n",
            "--2019-11-15 12:52:39--  https://www.dropbox.com/s/raw/9c02j9o9urumi58/saved_models.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca68176649748142826a6d109b7.dl.dropboxusercontent.com/cd/0/inline/AsbcBsZCCoPERwemjJ4nJs6zdGITk0PuiQ2JhTinwaO0yruC08h5e0IjosGJOtzGk190wv0ichTrmjr2_eWbRi6DVAyZqaJZJIVSRqCq__J6jW_Ss19JHzyM_MEd0rOqZrY/file# [following]\n",
            "--2019-11-15 12:52:39--  https://uca68176649748142826a6d109b7.dl.dropboxusercontent.com/cd/0/inline/AsbcBsZCCoPERwemjJ4nJs6zdGITk0PuiQ2JhTinwaO0yruC08h5e0IjosGJOtzGk190wv0ichTrmjr2_eWbRi6DVAyZqaJZJIVSRqCq__J6jW_Ss19JHzyM_MEd0rOqZrY/file\n",
            "Resolving uca68176649748142826a6d109b7.dl.dropboxusercontent.com (uca68176649748142826a6d109b7.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uca68176649748142826a6d109b7.dl.dropboxusercontent.com (uca68176649748142826a6d109b7.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AsbydKmPHW95Fc3zrB43Fc1tdI7uV4AKYgR2ruTfiVVla9f_fVvHj1f-f4g3fGidlnaxNQAcffAoUvjV0jSRylQIGYiYCLRZu0w4-Wk0xv_wyj_PKPb8wm1TsQk_rNkbNRB0Tud60hVGjOoGPSDNnGikd8XwMwL549anG1nOucINaFGhw9PgicnbFbun637MKPxRFaBIwgX5nlOT9JIPiN25BtwzirIinxlKcVm9BljRJ7dddQ-MMPJAK29bfJmGhtCS3HDgKvI8Akr_8U46rfteRnpgKeFxNgPulJ2qoNG5-ny7Xc9_4SDxSL73BN8I7sBvRbWTCupUTSIBgspiSLcWa8kOsC47xHk8Jd-CpKN7Xw/file [following]\n",
            "--2019-11-15 12:52:40--  https://uca68176649748142826a6d109b7.dl.dropboxusercontent.com/cd/0/inline2/AsbydKmPHW95Fc3zrB43Fc1tdI7uV4AKYgR2ruTfiVVla9f_fVvHj1f-f4g3fGidlnaxNQAcffAoUvjV0jSRylQIGYiYCLRZu0w4-Wk0xv_wyj_PKPb8wm1TsQk_rNkbNRB0Tud60hVGjOoGPSDNnGikd8XwMwL549anG1nOucINaFGhw9PgicnbFbun637MKPxRFaBIwgX5nlOT9JIPiN25BtwzirIinxlKcVm9BljRJ7dddQ-MMPJAK29bfJmGhtCS3HDgKvI8Akr_8U46rfteRnpgKeFxNgPulJ2qoNG5-ny7Xc9_4SDxSL73BN8I7sBvRbWTCupUTSIBgspiSLcWa8kOsC47xHk8Jd-CpKN7Xw/file\n",
            "Reusing existing connection to uca68176649748142826a6d109b7.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27275975 (26M) [application/zip]\n",
            "Saving to: ‘saved_models.zip’\n",
            "\n",
            "saved_models.zip    100%[===================>]  26.01M  77.5MB/s    in 0.3s    \n",
            "\n",
            "2019-11-15 12:52:40 (77.5 MB/s) - ‘saved_models.zip’ saved [27275975/27275975]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhTmulWBH1Ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f2824dc5-2a38-479f-9258-900fc3206ed4"
      },
      "source": [
        "! unzip saved_models.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  saved_models.zip\n",
            "  inflating: saved_models/weights-improvement-09-1.8647.hdf5  \n",
            "  inflating: saved_models/weights-improvement-29-1.4653.hdf5  \n",
            "  inflating: saved_models/weights-improvement-49-1.3420.hdf5  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1Dwgj3nHpBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "cd24f365-7894-4c5a-b56c-e9aa144f31e7"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Activation\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjD_honVHpBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQ_LENGTH = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSQdPa00HpBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildmodel(VOCABULARY):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(256, input_shape = (SEQ_LENGTH, 1), return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(256))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(VOCABULARY, activation = 'softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJPWRROsINBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "0aff6aaa-65da-4cc9-a4d9-18b109b3625f"
      },
      "source": [
        "!wget https://www.dropbox.com/s/e0xheuvov8fev09/wonderland.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-15 12:54:31--  https://www.dropbox.com/s/e0xheuvov8fev09/wonderland.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/e0xheuvov8fev09/wonderland.txt [following]\n",
            "--2019-11-15 12:54:31--  https://www.dropbox.com/s/raw/e0xheuvov8fev09/wonderland.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc18de5154a05a7dcca493081240.dl.dropboxusercontent.com/cd/0/inline/AsYPjPN3gikU9aL4JC3m9A26-tiOxqVWxCP2n8Qcnum__GgmmZhMtQHmr97d40C7vXpAvuug5FEg5WN_EP-6fXcr5C7nBFJJU5cOPEJT35y6x8YTu8Ag8KCb6huLQYeDmkI/file# [following]\n",
            "--2019-11-15 12:54:31--  https://uc18de5154a05a7dcca493081240.dl.dropboxusercontent.com/cd/0/inline/AsYPjPN3gikU9aL4JC3m9A26-tiOxqVWxCP2n8Qcnum__GgmmZhMtQHmr97d40C7vXpAvuug5FEg5WN_EP-6fXcr5C7nBFJJU5cOPEJT35y6x8YTu8Ag8KCb6huLQYeDmkI/file\n",
            "Resolving uc18de5154a05a7dcca493081240.dl.dropboxusercontent.com (uc18de5154a05a7dcca493081240.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc18de5154a05a7dcca493081240.dl.dropboxusercontent.com (uc18de5154a05a7dcca493081240.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173595 (170K) [text/plain]\n",
            "Saving to: ‘wonderland.txt’\n",
            "\n",
            "\rwonderland.txt        0%[                    ]       0  --.-KB/s               \rwonderland.txt      100%[===================>] 169.53K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-11-15 12:54:32 (12.1 MB/s) - ‘wonderland.txt’ saved [173595/173595]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgSRCSIdHpB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('/content/wonderland.txt', encoding = 'utf8')\n",
        "raw_text = file.read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAZdMgIiHpCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3443f63d-e3ce-4990-f752-d35d2beb9d1b"
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "print(chars)\n",
        "bad_chars = ['#', '*', '@', '_', '\\ufeff']\n",
        "for i in range(len(bad_chars)):\n",
        "    raw_text = raw_text.replace(bad_chars[i],\"\")\n",
        "chars = sorted(list(set(raw_text)))\n",
        "print(chars)\n",
        "VOCABULARY = len(chars)\n",
        "\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '#', '$', '%', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”', '\\ufeff']\n",
            "['\\n', ' ', '!', '$', '%', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8himGZAHpCU",
        "colab_type": "text"
      },
      "source": [
        "Now that our model has been defined and we have preprocessed our input file and redefinded our vocabulary, as in train.ipynb file, we are ready to proceed. The best model with least loss as we obtained in the last epoch of training is loaded and the model is build and recompiled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RstfPjgsHpCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "39bf7160-fe3f-46a1-91d0-a33a2fe4f856"
      },
      "source": [
        "filename = '/content/saved_models/weights-improvement-49-1.3420.hdf5'\n",
        "model = buildmodel(VOCABULARY)\n",
        "model.load_weights(filename)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZeOryg_HpCe",
        "colab_type": "text"
      },
      "source": [
        "The initital 100 character seed used for generating text are the first few characters of the famous children book 'The Cat in the Hat' by Dr. Seuss available [here](http://www.stylist.co.uk/books/100-best-opening-lines-from-childrens-books#gallery-1). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSoCraLGHpCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_text = ' the sun did not shine, it was too wet to play, so we sat in the house all that cold, cold wet day. '# we sat here we two and we said how we wish we had something to do.'\n",
        "initial_text = [char_to_int[c] for c in initial_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npDiYPmnHpCn",
        "colab_type": "text"
      },
      "source": [
        "Starting with the initial seed next 1000 characters are generated by shifting the 100 character input window for generating the next character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmXNFa_LHpCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GENERATED_LENGTH = 1000\n",
        "test_text = initial_text\n",
        "generated_text = []\n",
        "\n",
        "for i in range(1000):\n",
        "    X = np.reshape(test_text, (1, SEQ_LENGTH, 1))\n",
        "    next_character = model.predict(X/float(VOCABULARY))\n",
        "    index = np.argmax(next_character)\n",
        "    generated_text.append(int_to_char[index])\n",
        "    test_text.append(index)\n",
        "    test_text = test_text[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIj4lHURHpCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "9f02cc90-2322-4678-8c5d-091270b6c283"
      },
      "source": [
        "print(''.join(generated_text))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "and the white rabbit was a little botk of the sable of the garden, the mock turtle said nothing on the soog, and she shought thene was not a moment to be no mistle thing, and she was soomding of the soecs of the gad she was soo mloe ald spok as the mock turtle with a siate oige back on the shate.\n",
            "\n",
            "‘well, it doesn’t kike the bar,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said the king. \n",
            "‘i dan’t remember it,’ said \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM1KOQpmIuYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "aZoRCOLCHpC2",
        "colab_type": "text"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "We can see the 1000 characters as generated by the model and there are a lot of things to conclude-\n",
        "\n",
        "* Most of the words generated by the model are proper english words, although there are exceptions at many places. This shows that the model has a good understanding of how letters are combined to form different words. Even though it is very obvious to do for a human, but for a computer model to give a reasonable performance at word formation is itself a huge feat.\n",
        "* There are a few drawbacks as well. One of them is that the model often suggests 'and', both after a comma and a full stop which may be correct in case 1, but is always wrong for case 2. Also some incorrected words are generated as well.\n",
        "* The model has understood the use of inverted quotes and apostrophes quite nicely. All the inverted commas are closed appropriately and succeded by proper endings, such as 'said the king.'.\n",
        "* The model has understood the use of spaces and indentations quite well. After each of the 'said the king' lines, succeding text always begins in the new line, giving the generated text, a clean look.\n",
        "* The model has almost no understanding of the context of the initial seed. The iniital text consists of a cold wet day and how playing is difficult on such a day, but generated text talks about rabbits and turtles (which still seems reasonable), but then  starts a conversation of king which is quite absurd. However results on this are expected to improve once the model is trained on a variety of texts rather than just a single book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLn83kQIHpC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}